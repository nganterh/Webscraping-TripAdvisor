{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>WebScraping TripAdvisor</h1>\n",
    "\n",
    "---\n",
    "\n",
    "El código a continuación tiene por objetivo extraer la **[información solicitada](https://github.com/mozilla/geckodriver/releases/download/v0.28.0/geckodriver-v0.28.0-win64.zip \"Word en Google Drive\")**, desde la página de **[TripAdvisor](https://www.tripadvisor.cl/Restaurants-g294305-Santiago_Santiago_Metropolitan_Region.html \"Web TripAdvisor\")** para Ximena. La siguiente celda sólo cumple con el propósito de **silenciar las posibles advertencias** que pudieran levantarse al correr el código, pero no aportan mayormente a la comprensión del proceso por parte del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda anterior asegurará que no se desplieguen advertencias innecesarias para la correcta comprensión y lectura de este informe. A continuación se darán las **instrucciones para instalar las librerías** necesarias para correr el código, cuestión que requiere de un comando para ello, por lo que las instrucciones se despliegan como impresión de una celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si es la primera vez que corre este programa, por favor abra la terminal PowerShell de Anaconda e ingrese el siguiente comando: \"\u001b[4mpip install -r C:\\Users\\nicol\\Proyectos\\GitHub\\Webscraping-TripAdvisor\\requirements.txt\u001b[4m\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(f'Si es la primera vez que corre este programa, por favor abra la terminal PowerShell de Anaconda' +\n",
    "      f' e ingrese el siguiente comando: \"\\033[4mpip install -r {os.getcwd()}\\\\requirements.txt\\033[4m\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera parte fundamental de todo programa, corresponde a la **importación de librerías de Python**. Si acaso hubiera errores en esta primera celda, se aconseja contactar a Nicolás Ganter a su correo: nicolas@ganter.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del código, hay ciertas **variables que es preferible tener en especial consideración**. Entre ellas, encontramos la ubicación del *driver* para *Selenium* que permitirá lanzar una instancia de *Firefox* para navegar la página y extraer los enlaces requeridos en la primera etapa de *webcrawling*. Si aún no ha instalado el driver, acceda a este **[link de descarga](https://github.com/mozilla/geckodriver/releases/download/v0.28.0/geckodriver-v0.28.0-win64.zip \"geckodriver download link\")**, extraiga el paquete y mueva los documentos a la carpeta de binarios de las librerías de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "geckodriver_path = r'C:\\Users\\nicol\\anaconda3\\Library\\bin\\geckodriver'\n",
    "time_id = datetime.today().strftime('%Y%m%d')\n",
    "basic_url = 'https://www.tripadvisor.cl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:56456</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:56455/status' target='_blank'>http://127.0.0.1:56455/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>17.02 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:56456' processes=3 threads=6, memory=17.02 GB>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Webcrawling de los restaurantes</h2>\n",
    "La siguiente celda se encargará de la **extracción de los enlaces** asociados a cada restaurante en las páginas especificadas mediante el enlace de la segunda línea. En este caso, se extraerán los restaurantes de Santiago de Chile. Al final de la celda se imprime la cantidad de restaurantes extraídos, la cantidad de restaurantes disponibles según la página, y el porcentaje capturado por el programa. Nótese que el proceso toma algo así como 10 minutos, por lo que se utilizará un atajo mediante *pickles* (estructura de datos propia de este lenguaje de programación) y se especificará la fecha de captura de la información asociada a éste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información cargada del pickle 20210205_4830_urls.pickle extraído el 05 de febrero del 2021.\n",
      "Se obtuvieron 4830 restaurantes de 4848 lo que corresponde a una extracción del 99.63%\n",
      "Este proceso tomó 12.34 segundos en correr.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "url = basic_url + '/Restaurants-g294305-Santiago_Santiago_Metropolitan_Region.html'\n",
    "info = utils.info_restaurants(url, geckodriver_path)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "dict_pickles = utils.check_files(dir_files=cwd, keyword='urls')\n",
    "\n",
    "if len(dict_pickles) == 0:\n",
    "    urls = utils.gen_pickle(url, geckodriver_path, info['pages'], basic_url, time_id)\n",
    "\n",
    "else:\n",
    "    last_pickle = utils.last_pickle(dict_pickles)\n",
    "    with open(last_pickle, 'rb') as file:\n",
    "        urls = pickle.load(file)\n",
    "    \n",
    "print('Se obtuvieron {} restaurantes de {} lo que corresponde a una extracción del {}%'\n",
    "      .format(len(urls), info['max_restaurants'], round(len(urls) / info['max_restaurants'] * 100, 2)))\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Este proceso tomó {round(stop-start, 2)} segundos en correr.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Webscraping de los restaurantes</h2>\n",
    "Con esto concluye la parte más compleja y crítica de la recopilación de enlaces para los restaurantes. No obstante esta tarea continúa luego a nivel de comentarios, **a continuación se procederá a extraer la información solicitada** para cada uno de los restaurantes en la lista. Dado que se utilizan estrategias de computación paralela, no es posible observar el avance, sino abriendo el *Dashboard* cuyo link se encuentra bajo la cuarta celda del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardó \"20210205_dataframe_of_4830_restaurants.pickle\" en \"C:\\Users\\nicol\\Proyectos\\GitHub\\Webscraping-TripAdvisor\".\n",
      "Este proceso tomó 1909.57 segundos en correr.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dict_dataframes = utils.check_files(dir_files=cwd, keyword='dataframe')\n",
    "\n",
    "if len(dict_dataframes) == 0:\n",
    "    futures = [client.submit(utils.get_restaurant, url_restaurant) for url_restaurant in list(set(urls))]\n",
    "    results = client.gather(futures)\n",
    "    \n",
    "    dict_structure = {'id':[], 'Nombre restaurante':[], 'Promedio de calificaciones':[],\n",
    "                      'N° de opiniones':[], 'Calificación de viajeros por categoría':[],\n",
    "                      'Toman medidas de seguridad':[], 'Rankings':[],\n",
    "                      'Tipo de comida y servicios':[], 'url':[]}\n",
    "    \n",
    "    df_restaurants = utils.build_dataframe(dict_structure, results, time_id)\n",
    "    df_restaurants.to_pickle(f'{time_id}_dataframe_of_{df_restaurants.shape[0]}_restaurants.pickle')\n",
    "    print(f'Se guardó \"{time_id}_dataframe_of_{df_restaurants.shape[0]}_restaurants.pickle\" en \"{os.getcwd()}\".')\n",
    "    \n",
    "else:\n",
    "    last_pickle = utils.last_pickle(dict_dataframes)\n",
    "    with open(last_pickle, 'rb') as file:\n",
    "        df_restaurants = pickle.load(file)\n",
    "    \n",
    "stop = time.time()\n",
    "print(f'Este proceso tomó {round(stop-start, 2)} segundos en correr.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Webcrawling de los comentarios</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardó \"20210205_4321_review_urls.pickle\" en \"C:\\Users\\nicol\\Proyectos\\GitHub\\Webscraping-TripAdvisor\".\n",
      "Este proceso tomó 1704.29 segundos en correr. Se dispone aproximadamente de 43210 comentarios para extraer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dict_files = utils.check_files(dir_files=cwd, keyword='review_urls')\n",
    "\n",
    "if len(dict_files) == 0:\n",
    "    futures = [client.submit(utils.review_urls, url_restaurant) for url_restaurant in list(set(urls))]\n",
    "    results = client.gather(futures)\n",
    "    \n",
    "    dict_reviews = {key:value for key, value in results if isinstance(value, list)}\n",
    "    n_reviews = len(dict_reviews.values())\n",
    "    \n",
    "    with open(f'{time_id}_{n_reviews}_review_urls.pickle', 'wb') as file:\n",
    "        pickle.dump(dict_reviews, file)\n",
    "    \n",
    "    print(f'Se guardó \"{time_id}_{n_reviews}_review_urls.pickle\" en \"{os.getcwd()}\".')\n",
    "    \n",
    "else:\n",
    "    last_pickle = utils.last_pickle(dict_files)\n",
    "    with open(last_pickle, 'rb') as file:\n",
    "        dict_reviews = pickle.load(file)\n",
    "    \n",
    "stop = time.time()\n",
    "print(f'Este proceso tomó {round(stop-start, 2)} segundos en correr.',\n",
    "      'Se dispone aproximadamente de {} comentarios para extraer.\\n'.format(len(dict_reviews.values())*10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Webscraping de los comentarios</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardó \"20210121_dataframe_of_205575_scraped_reviews.pickle\" en \"C:\\Users\\nicol\\Proyectos\\WebScraping TripAdvisor\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_review</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_stayed</th>\n",
       "      <th>response_body</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>useful_votes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.877095e+18</th>\n",
       "      <td>4/08/2017</td>\n",
       "      <td>Fuimos hace una semana con mi novia a conocer ...</td>\n",
       "      <td>08/2017</td>\n",
       "      <td>None</td>\n",
       "      <td>ignaciosaezcl</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.557562e+18</th>\n",
       "      <td>22/11/2016</td>\n",
       "      <td>A mi hijo mayor le encanta la comida China, es...</td>\n",
       "      <td>10/2016</td>\n",
       "      <td>None</td>\n",
       "      <td>DanaeAchurra</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.557562e+18</th>\n",
       "      <td>26/10/2016</td>\n",
       "      <td>Dentro de esta comuna este restaurantes es muy...</td>\n",
       "      <td>10/2016</td>\n",
       "      <td>None</td>\n",
       "      <td>Carmengloria00</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.557562e+18</th>\n",
       "      <td>22/10/2016</td>\n",
       "      <td>Vez que puedo paso a buscar comida para llevar...</td>\n",
       "      <td>09/2016</td>\n",
       "      <td>None</td>\n",
       "      <td>Pancho89</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.557562e+18</th>\n",
       "      <td>7/01/2020</td>\n",
       "      <td>Enormes platos de comida china. ¡Puedes compar...</td>\n",
       "      <td>12/2019</td>\n",
       "      <td>None</td>\n",
       "      <td>HavBagWiLLTravel</td>\n",
       "      <td>182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.176595e+18</th>\n",
       "      <td>20/07/2018</td>\n",
       "      <td>La comida es rica, ninguna maravilla. El preci...</td>\n",
       "      <td>10/2017</td>\n",
       "      <td>None</td>\n",
       "      <td>iaguerok</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.176595e+18</th>\n",
       "      <td>22/03/2018</td>\n",
       "      <td>Sin negar el tamaño de los platos, que llega a...</td>\n",
       "      <td>03/2018</td>\n",
       "      <td>None</td>\n",
       "      <td>Rodrigo M</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.176595e+18</th>\n",
       "      <td>12/12/2017</td>\n",
       "      <td>Fuimos a almorzar con dos compañeros de trabaj...</td>\n",
       "      <td>10/2017</td>\n",
       "      <td>None</td>\n",
       "      <td>LConsoloS</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.176595e+18</th>\n",
       "      <td>22/11/2017</td>\n",
       "      <td>Para un almuerzo rápido, salva. Tiene para tod...</td>\n",
       "      <td>11/2017</td>\n",
       "      <td>None</td>\n",
       "      <td>DV1978</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.176595e+18</th>\n",
       "      <td>10/11/2017</td>\n",
       "      <td>A pesar de que cierran temprano, es un opción ...</td>\n",
       "      <td>10/2017</td>\n",
       "      <td>None</td>\n",
       "      <td>Daniel A</td>\n",
       "      <td>152</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205575 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date_review  ... useful_votes\n",
       "id                         ...             \n",
       "-1.877095e+18   4/08/2017  ...          0.0\n",
       " 8.557562e+18  22/11/2016  ...          0.0\n",
       " 8.557562e+18  26/10/2016  ...          0.0\n",
       " 8.557562e+18  22/10/2016  ...          0.0\n",
       " 8.557562e+18   7/01/2020  ...          0.0\n",
       "...                   ...  ...          ...\n",
       " 9.176595e+18  20/07/2018  ...          0.0\n",
       " 9.176595e+18  22/03/2018  ...          0.0\n",
       " 9.176595e+18  12/12/2017  ...          0.0\n",
       " 9.176595e+18  22/11/2017  ...          0.0\n",
       " 9.176595e+18  10/11/2017  ...          0.0\n",
       "\n",
       "[205575 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este proceso tomó 9622.78 segundos en correr. Se extrajeron 205575 comentarios.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dict_files = utils.check_files(dir_files=cwd, keyword='scraped_reviews')\n",
    "url_reviews = utils.prepare_urls(dict_reviews)\n",
    "\n",
    "if len(dict_files) == 0:\n",
    "    futures = [client.submit(utils.get_reviews, url) for url in url_reviews]\n",
    "    results = client.gather(futures)\n",
    "    \n",
    "    dict_structure = {'id':[], 'date_review':[], 'comments':[], 'date_stayed':[], 'response_body':[],\n",
    "                      'user_name':[], 'user_reviews':[], 'useful_votes':[]}\n",
    "\n",
    "    df_reviews = utils.build_dataframe(dict_structure, results, time_id)\n",
    "    df_pathname = f'{time_id}_dataframe_of_{df_reviews.shape[0]}_scraped_reviews.pickle'\n",
    "\n",
    "    df_reviews.to_pickle(df_pathname)\n",
    "    print(f'Se guardó \"{df_pathname}\" en \"{os.getcwd()}\"')\n",
    "        \n",
    "else:\n",
    "    last_pickle = utils.last_pickle(dict_files)\n",
    "    df_reviews = pd.read_pickle(last_pickle)\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Este proceso tomó {round(stop-start, 2)} segundos en correr.',\n",
    "      'Se extrajeron {} comentarios.\\n'.format(df_reviews.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Generación de tablas</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "start = time.time()\n",
    "df_restaurants.to_excel(f'{time_id}_excel_with_{df_restaurants.shape[0]}_restaurants.xlsx')\n",
    "df_reviews.to_excel(f'{time_id}_excel_with_{df_reviews.shape[0]}_reviews.xlsx')\n",
    "stop = time.time()\n",
    "\n",
    "print(f'Este proceso tomó {round(stop-start, 2)} segundos en correr.',\n",
    "      'Se extrajeron {} comentarios.\\n'.format(df_reviews.shape[0]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6572459385993448040 \n",
      "\n",
      " 6572459385993448040\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import copy\n",
    "\n",
    "df_restest = df_restaurants.copy()\n",
    "df_revtest = df_reviews.copy()\n",
    "\n",
    "id_restaurants = set(df_restest.index.to_list())\n",
    "id_reviews = set(df_revtest.index.to_list())\n",
    "\n",
    "print(hash(url_reviews[0]['identifier']), '\\n\\n', hash(urls[0]))\n",
    "#.intersection(id_reviews)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
